{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.0 torchtext==0.16.2 numpy\\<2.0\n",
        "!pip install portalocker>=2.0.0\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "EfJlvzW1sUuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f72d258"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy\n",
        "import portalocker\n",
        "import torchdata\n",
        "import math\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.transforms import SentencePieceTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f799fb1a"
      },
      "source": [
        "## Tokenisation (BPE) / Construction du vocabulaire :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6889046a"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'de'\n",
        "LANGUAGE_MAP = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iter_for_spm = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "\n",
        "#Creation d'un fichier temporaire contenant les phrases\n",
        "temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8')\n",
        "temp_file_path = temp_file.name\n",
        "\n",
        "try:\n",
        "    #Ecrire toutes les phrases (anglais et allemand) dans le fichier\n",
        "    for src_sentence, tgt_sentence in train_iter_for_spm:\n",
        "        temp_file.write(src_sentence.strip() + '\\n')\n",
        "        temp_file.write(tgt_sentence.strip() + '\\n')\n",
        "finally:\n",
        "    temp_file.close()\n",
        "\n",
        "#Entrainement du tokenizer avec SPM\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=temp_file_path,\n",
        "    model_prefix='bpe',\n",
        "    vocab_size=10000,\n",
        "    model_type='bpe',\n",
        "    bos_id=BOS_IDX,\n",
        "    eos_id=EOS_IDX,\n",
        "    unk_id=UNK_IDX,\n",
        "    pad_id=PAD_IDX,\n",
        "    character_coverage=1.0,\n",
        "    byte_fallback=True\n",
        ")\n",
        "\n",
        "#Clean up\n",
        "os.remove(temp_file_path)\n",
        "\n",
        "# L'itérateur a été consommé on Re-initialise\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "\n",
        "# Tokenizers pour English and German : token_transform[LANGUAGE](\" \") -> renvoie les tokens associés à la phrase\n",
        "token_transform = {\n",
        "    SRC_LANGUAGE: SentencePieceTokenizer(\"bpe.model\"),\n",
        "    TGT_LANGUAGE: SentencePieceTokenizer(\"bpe.model\")\n",
        "}\n",
        "\n",
        "#Parcours toutes les phrases du dataset et renvoie les tokens\n",
        "def yield_tokens(data_iter, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "    for sample in data_iter:\n",
        "        yield token_transform[language](sample[language_index[language]])\n",
        "\n",
        "vocab_transform = {}\n",
        "for lang in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    current_train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    vocab_transform[lang] = build_vocab_from_iterator(\n",
        "        yield_tokens(current_train_iter, lang),\n",
        "        min_freq=1,\n",
        "        specials=special_symbols,\n",
        "        special_first=True\n",
        "    )\n",
        "    vocab_transform[lang].set_default_index(UNK_IDX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BOvlQeDjsHy",
        "outputId": "94c8e7f4-df9a-4191-fbb6-90b2584e7532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁The',\n",
              " '▁to',\n",
              " 'ken',\n",
              " 'iz',\n",
              " 'er',\n",
              " '▁is',\n",
              " '▁prep',\n",
              " 'ro',\n",
              " 'cess',\n",
              " 'ing',\n",
              " '▁the',\n",
              " '▁text',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "token_transform[SRC_LANGUAGE](\"The tokenizer is preprocessing the text.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a6b60d9"
      },
      "source": [
        "## Création du dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63d218cf"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Fonction Helper qui applique une suite de transformation\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "\n",
        "# Ajoute BOS/EOS au token et créer le tenseur\n",
        "def add_bos_and_eos(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "#Tokenisation complète\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               add_bos_and_eos) #ajoute BOS/EOS et créer le tenseur\n",
        "\n",
        "\n",
        "#batch utilisable\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1a4bf00"
      },
      "source": [
        "Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "686e070e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 128\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "size_dataloader = len(list(train_dataloader))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430a453f"
      },
      "source": [
        "## MODELE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a975571a"
      },
      "source": [
        "PositionnalEncoding sinusoidale classique:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8274cf53"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        sum_embed = token_embedding + self.pos_embedding[:token_embedding.size(0), :]\n",
        "        return self.dropout(sum_embed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b170699"
      },
      "source": [
        "Creation des masques d'attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e817c23"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(mask_size):\n",
        "    return torch.triu(torch.ones((mask_size, mask_size), device=DEVICE, dtype=torch.bool),diagonal=1)\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len).to(DEVICE)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbab96fa"
      },
      "source": [
        "Modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35599483"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        outs = self.embedding(tokens.long())\n",
        "        return outs  * math.sqrt(self.emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "450e64fb"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.unembed = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        #embedding + positional encoding\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        #Transformer complet (encodeur + décodeur)\n",
        "        outs = self.transformer(src_emb,tgt_emb,src_mask=src_mask,tgt_mask=tgt_mask,\n",
        "                                src_key_padding_mask=src_padding_mask,tgt_key_padding_mask=tgt_padding_mask,\n",
        "                                memory_key_padding_mask=memory_key_padding_mask)\n",
        "        #projections\n",
        "        logits = self.unembed(outs)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "426f4b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea672932-740e-41cd-9396-e15b9b34e1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "#hyperparameters\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 2048\n",
        "NUM_ENCODER_LAYERS = 4\n",
        "NUM_DECODER_LAYERS = 4\n",
        "lr=0.0003\n",
        "NUM_EPOCHS=10\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "#Initialisation des poids du transformer par xavier_uniform (évite les vanishing gradient)\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1: #pas les biais\n",
        "        nn.init.xavier_uniform_(p)\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "#loss et optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0003, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34eb02f9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d930eb04"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, loss_fn, train_dataloader):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        # Décalage\n",
        "        tgt_input = tgt[:-1, :]      # On enlève EOS : ce que le decodeur voit\n",
        "        tgt_output = tgt[1:, :]      # On enlève BOS : ce que le decodeur doit prédire\n",
        "\n",
        "        # Création des masks avec la fonction précédente\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        # Forward\n",
        "        logits = model(src,tgt_input,src_mask,tgt_mask,src_padding_mask,tgt_padding_mask,src_padding_mask)\n",
        "\n",
        "        # Loss\n",
        "        optimizer.zero_grad() #remettre à 0 les gradients\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]),tgt_output.reshape(-1))\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_losses), train_losses\n",
        "\n",
        "\n",
        "def evaluate(model, loss_fn, val_dataloader):\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        # Décalage\n",
        "        tgt_input = tgt[:-1, :] # On enlève EOS : ce que le decodeur voit\n",
        "        tgt_output = tgt[1:, :] # On enlève BOS : ce que le decodeur doit prédire\n",
        "\n",
        "        # Création des masks avec la fonction précédente\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        logits = model(src,tgt_input,src_mask,tgt_mask,src_padding_mask,tgt_padding_mask,src_padding_mask)\n",
        "\n",
        "        #loss\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]),tgt_output.reshape(-1))\n",
        "        val_losses.append(loss.item())\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "      return total_loss / len(val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7511c1e0",
        "outputId": "f7e19158-f6cc-4ae3-9fdb-b6259ba9b76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train loss: 5.0683 | Val loss: 4.3053\n",
            "Epoch 2 | Train loss: 3.9511 | Val loss: 3.7779\n",
            "Epoch 3 | Train loss: 3.4936 | Val loss: 3.4729\n",
            "Epoch 4 | Train loss: 3.0142 | Val loss: 2.9634\n",
            "Epoch 5 | Train loss: 2.4868 | Val loss: 2.5166\n",
            "Epoch 6 | Train loss: 2.0671 | Val loss: 2.2886\n",
            "Epoch 7 | Train loss: 1.7717 | Val loss: 2.1497\n",
            "Epoch 8 | Train loss: 1.5397 | Val loss: 2.0597\n",
            "Epoch 9 | Train loss: 1.3470 | Val loss: 2.0368\n",
            "Epoch 10 | Train loss: 1.1930 | Val loss: 2.0381\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss, _ = train_epoch(transformer, optimizer, loss_fn, train_dataloader)\n",
        "    val_loss = evaluate(transformer, loss_fn, val_dataloader)\n",
        "    print(f\"Epoch {epoch} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a0dff95"
      },
      "source": [
        "## INFERENCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3316fd4d"
      },
      "source": [
        "BEAM SEARCH pour la traduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f04913a"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def beam_search_decode(model, src, src_mask, max_len, start_symbol, K=5,length_penalty=0.7):\n",
        "    model.eval()\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        memory = model.encode(src, src_mask)\n",
        "        init_seq = torch.full((1, src.shape[1]), start_symbol, dtype=torch.long, device=DEVICE)\n",
        "        beams = [(init_seq, 0.0, False)]\n",
        "\n",
        "        for _ in range(max_len - 1):\n",
        "            candidates = []\n",
        "\n",
        "            #Si toutes les hypothèses du beam en cours ont déjà produit un token EOS on a fini d'étudier src\n",
        "            if all(finished for (_, _, finished) in beams):\n",
        "                break\n",
        "\n",
        "            for seq, score, finished in beams: #on va etudier toutes les hypothèses du beam\n",
        "                if finished:\n",
        "                    #Si l'hypothèse a atteint EOS alors on l'ajoute à candidat et on passe à la prochaine hypothèse\n",
        "                    candidates.append((seq, score, True))\n",
        "                    continue\n",
        "\n",
        "                #sinon on génère :\n",
        "                tgt_mask = generate_square_subsequent_mask(seq.size(0)).to(DEVICE)\n",
        "                out = model.decode(seq, memory, tgt_mask)\n",
        "                logits = model.unembed(out)\n",
        "                log_probs = F.log_softmax(logits[-1, 0, :], dim=-1)\n",
        "\n",
        "                #On va regarder les K meilleurs prochains tokens et itérer dessus pour noter leur score respectif\n",
        "                topk_log_probs, topk_tokens = torch.topk(log_probs, K)\n",
        "                for j in range(K):\n",
        "                    tok = topk_tokens[j].item()\n",
        "                    new_seq = torch.cat([seq, torch.tensor([[tok]], dtype=torch.long, device=DEVICE)],dim=0)\n",
        "                    new_score = score + topk_log_probs[j].item()\n",
        "                    new_finished = (tok == EOS_IDX) #si le prochain token est EOS alors on a fini cette hypotèse\n",
        "                    candidates.append((new_seq, new_score, new_finished))\n",
        "\n",
        "            candidates.sort(key=lambda x: x[1] / (x[0].size(0) ** length_penalty), reverse=True) #length_penalty pour eviter que les séquences courtes soient privilégiées\n",
        "            beams = candidates[:K] #on garde que les K meilleurs hypothèses (il y en a max K^2) comme ca on en a seulement K à chaque fois (sinon suite géometrique )\n",
        "\n",
        "        #Selection du meilleur beam\n",
        "        best_seq, _, _ = max(beams, key=lambda x: x[1] / (x[0].size(0) ** length_penalty))\n",
        "        return best_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75dc212b"
      },
      "source": [
        "TRADUCTEUR : Anglais -> Allemand\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kdsbV6Scozh"
      },
      "outputs": [],
      "source": [
        "def detokenize_sentencepiece(tokens):\n",
        "    text = \"\".join(tokens)\n",
        "    return text.replace(\"▁\", \" \").strip()\n",
        "\n",
        "\n",
        "def Beam_translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "\n",
        "    tgt_tokens = beam_search_decode(model,src,src_mask,max_len=num_tokens + 5,start_symbol=BOS_IDX,K=5,length_penalty=0.7).flatten()\n",
        "\n",
        "    tokens = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().tolist()))\n",
        "    sentence = detokenize_sentencepiece(tokens)\n",
        "    sentence = sentence.replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").strip()\n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU score :"
      ],
      "metadata": {
        "id": "UeEwhMS0lKjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "transformer.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for example in test_data:\n",
        "        src_sentence = example[\"en\"]\n",
        "        tgt_sentence = example[\"de\"]\n",
        "\n",
        "        pred = Beam_translate(transformer, src_sentence)\n",
        "\n",
        "        predictions.append(pred)\n",
        "        references.append(tgt_sentence)\n",
        "\n",
        "bleu = sacrebleu.corpus_bleu(\n",
        "    predictions,\n",
        "    [references],\n",
        "    tokenize=\"13a\"\n",
        ")\n",
        "\n",
        "print(\"BLEU score:\", bleu.score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342,
          "referenced_widgets": [
            "6fbfb40028624ede804f6b12864db9cc",
            "74d2a70821ed498d80089c2d6a0609ca",
            "673d4710c3c14c69a31c9682a0d06cae",
            "f31d636fdaff4639ae0772b0187cdeb5",
            "cac81263df12438e9e2e39df89824f21",
            "e636c87d25c9475d96a92036b8ecefb8",
            "8264e682352c44ba911dbdd14cda886b",
            "4cf2dd9ebd2848eaaa1e0f09219da02a",
            "86dd3110196848afbe992a5f0d031fd8",
            "6c24e33749ed4399af950f57f521a7e1",
            "8a78858bd1524f78858de0c1af9c2f2a",
            "614e954843be4802a2fcf81ff796b531",
            "6a35f83d69844361b5570d9f4da39dd1",
            "f818c8c2f14d4753a8361f53b6d45b37",
            "139adcf5bac64c939277bbbcbfd4c16f",
            "7d044fa9f8504c33ae3e2074b07fa8b1",
            "cb1b82ba378d45fbaedcea2b28576865",
            "d0fb5ca5cf3d4a6a8caefcc2b0b56bb2",
            "4422ebfd96594a05ae18700b634fff35",
            "271a260c88394292b68e712f6d009f76",
            "e6d575be468c47bcaee385e1be03b710",
            "5fda2a27d20d44d7bcb0addd18e20118",
            "f300bcddcf844e6b99efe93be2732839",
            "046fa95ac3494ecd85c087dd683d4fbe",
            "7c55f3d735a946da88c61bc7f8982c10",
            "1a1bded1a2e047a29685e991363b0fc1",
            "71912a9fd88246e1bf2966b04ae79d28",
            "cf1960eb76094f6191b611bb6a7768f1",
            "0cf22aa39300421380634dd33bd77ea2",
            "a8d5f1c123ec4d4c96eba72a75c5d421",
            "0ecff6df85ae42f2bbb71f42abb78a42",
            "f26d195d005740c598d07c0bd406c423",
            "700651b80529475da5f9b25cbd6cff06",
            "2e7b5f20f2b040fb9ae88b8568aa2356",
            "010d9160eb8245a28be429c113efd5dc",
            "843bd46a0b134cd4a29f0df27a287894",
            "3767b111fc864e63b74f83a47535bc80",
            "239874dd88914d4ab3bccd68e5608583",
            "8d58fd9d86424c87bb711d4b71fddec4",
            "dd114815eb0a417187ef6a2181c3a738",
            "9ed76e9a733e4b7a867998010e45982a",
            "558b414f023d4cf596cf35733eec4658",
            "93592e562b7d4b16b484d16c7e4be513",
            "775f7b1f77db44ac9bec03d15bd27053",
            "219561feff4a47aab6a4c78d545388ae",
            "665ca6fedee649888516dada893af1b5",
            "840d96e81a1f44a298ccb32c7bba0d5b",
            "cbc1f0764c654c0b85052bee4a1cc837",
            "01ae991c95524e69ad4a37a88195f3fe",
            "fb2d8d5692244138911b1c078a781a72",
            "f267184cfce44f268b4840f12f10187f",
            "b24804e16b674908a0b5f5d1f80f9e7e",
            "21a0410b26a048aaa9c2c7e0cae4b4d0",
            "a33a4b8e74534f508f8d4b3a5316aaca",
            "98b3a582af644ed786439c333895f9b7",
            "63d80896505c45fca41acbe78f59856c",
            "e56ba6e2da6e48fd927f2bfca9fcbc9f",
            "5ab9fe9c5bd24145b525bd5363d3adc7",
            "bbedf40ce4a94d4fa9272dd818ee9be9",
            "f33239c7fec646868c61194a4af630ef",
            "cd54af5779e546fd959f692c8a04bafb",
            "f3a191aa136c49d0be2d96d887e1a277",
            "d34c00956ec6477a8e813fb5f7a7356d",
            "9565099fe813490787b4afb0df30971f",
            "9d96de6696a84a3f9c31b07fd0043f4e",
            "0298a66dc1d3454999a66c49e8f0f5cd",
            "5510348a869942d4a6bdb0befb0fb421",
            "a375f1351f4d45898ff0b85c124657e1",
            "5e426b5f74da4a8093cd1218423874b8",
            "e4782202f501438780f7f01e27e5a062",
            "0d330f4a09fe4a9089daaca6868448a1",
            "f926cf1f98e04c21bf3d9c4617eef30c",
            "7722b8d2b0184e60be8bd37818fa735c",
            "7514167f72fb4110a574c32dde22d4bb",
            "065771eccd5c40d8b9f6c0bbf32e31a8",
            "a88ac66cbbd5404cb592307649088840",
            "ded299c46afb492eb0faee2537c0a4b2"
          ]
        },
        "id": "noXGYeWSlJBp",
        "outputId": "e97637c6-3fcb-4d2b-a449-71266662e5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fbfb40028624ede804f6b12864db9cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "614e954843be4802a2fcf81ff796b531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "val.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f300bcddcf844e6b99efe93be2732839"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e7b5f20f2b040fb9ae88b8568aa2356"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/29000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219561feff4a47aab6a4c78d545388ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63d80896505c45fca41acbe78f59856c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5510348a869942d4a6bdb0befb0fb421"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 33.00658512896013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Nk8Jm1XyyCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Idéalement, j’aurais dû évaluer sur exactement la version TorchText utilisée pour l’entraînement afin de garantir une parfaite cohérence. Cependant, le split test de TorchText posait un problème de chargement et nécessitait de refaire tout le pipeline. J’ai donc utilisé la version HuggingFace, très proche en contenu, et le score BLEU obtenu reste cohérent avec les benchmarks attendus."
      ],
      "metadata": {
        "id": "uAfIUonPyxa5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBbYOG3Uct8u",
        "outputId": "4d15643f-4bef-410f-edbc-b628e1e4aa66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eine Frau schläft auf dem Bett.\n",
            "Die Katze spielt mit dem Hund.\n",
            "Zwei Kinder spielen im Schnee.\n",
            "Ein Mann fährt auf einem Fahrrad die Straße entlang.\n",
            "Mehrere Personen sitzen draußen an einem Tisch.\n",
            "Ein Hund läuft über ein Feld.\n",
            "Eine Frau hält ein Baby in ihren Armen.\n",
            "Drei Männer stehen in der Nähe eines Autos.\n",
            "Ein Kind isst Eiscreme.\n",
            "Ich vergnügen sich, um zu essen.\n"
          ]
        }
      ],
      "source": [
        "print(Beam_translate(transformer, \"The woman is sleeping\"))\n",
        "print(Beam_translate(transformer, \"The cat is playing with the dog.\"))\n",
        "print(Beam_translate(transformer, \"Two children are playing in the snow.\"))\n",
        "print(Beam_translate(transformer, \"A man is riding a bicycle down the street.\"))\n",
        "print(Beam_translate(transformer, \"Several people are sitting at a table outside.\"))\n",
        "print(Beam_translate(transformer, \"A dog is running through a field.\"))\n",
        "print(Beam_translate(transformer, \"A woman is holding a baby in her arms.\"))\n",
        "print(Beam_translate(transformer, \"Three men are standing near a car.\"))\n",
        "print(Beam_translate(transformer, \"A child is eating ice cream.\"))\n",
        "print(Beam_translate(transformer, \"I'm hungry, I want to eat\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2936d5f5"
      },
      "source": [
        "A woman is sleeping on the bed. (mots en plus)\n",
        "\n",
        "A cat is playing with the dog.\n",
        "\n",
        "Two children are playing in the snow.\n",
        "\n",
        "A man is riding a bicycle down the street.\n",
        "\n",
        "Several people are sitting outside at a table.\n",
        "\n",
        "A dog is running across a field.\n",
        "\n",
        "A woman is holding a baby in her arms.\n",
        "\n",
        "Three men are standing near a car.\n",
        "\n",
        "A child is eating an ice cream.\n",
        "\n",
        "They are having fun to eat.(complétement faux quand on sort du type description d'image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7da2f5da"
      },
      "source": [
        "Conclusion :\n",
        "\n",
        "Dans l’ensemble, le modèle produit des traductions grammaticalement correctes et sémantiquement cohérentes pour des phrases simples de description. On observe toutefois une forte homogénéité dans les structures et le vocabulaire, qui reflète directement le biais du jeu de données utilisé (phrases descriptives, scènes neutres, langage standardisé, issu de descriptions d’images).\n",
        "\n",
        "Ce biais limite la diversité lexicale et la capacité de généralisation du modèle à des phrases plus complexes, abstraites ou hors domaine. Les résultats sont donc satisfaisants dans le cadre restreint du dataset, mais ils ne garantissent pas encore des performances robustes en conditions réelles ou sur des textes plus riches et variés."
      ]
    }
  ]
}
